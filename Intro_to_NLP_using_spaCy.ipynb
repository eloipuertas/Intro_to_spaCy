{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install spaCy\n",
    "\n",
    "* `pip install spacy` \n",
    "* `pip install gensim`\n",
    "* `pip install matplotlib`\n",
    "* `pip install pyLDAVis`\n",
    "\n",
    "### Install Models\n",
    "\n",
    "`python -m spacy download en_core_web_sm`\n",
    "\n",
    "`python -m spacy download de_core_news_sm`\n",
    "\n",
    "`python -m spacy download es_core_news_sm`\n",
    "\n",
    "`python -m spacy download en_core_web_md`\n",
    "\n",
    "`python -m spacy download de_core_news_md`\n",
    "\n",
    "`python -m spacy download es_core_news_md`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What’s spaCy?\n",
    "\n",
    "spaCy is a free, open-source library for advanced Natural Language Processing (NLP) in Python.\n",
    "\n",
    "spaCy is designed specifically for production use and helps you build applications that process and “understand” large volumes of text. It can be used to build information extraction or natural language understanding systems, or to pre-process text for deep learning.\n",
    "\n",
    "https://spacy.io/usage/spacy-101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feautures\n",
    "\n",
    "<table class=\"_59fbd182\"><thead><tr class=\"_8a68569b\"><th class=\"_2e8d2972\">Name</th><th class=\"_2e8d2972\">Description</th></tr></thead><tbody><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><strong>Tokenization</strong></td><td class=\"_5c99da9a\">Segmenting text into words, punctuations marks etc.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><strong>Part-of-speech</strong> (POS) <strong>Tagging</strong></td><td class=\"_5c99da9a\">Assigning word types to tokens, like verb or noun.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><strong>Dependency Parsing</strong></td><td class=\"_5c99da9a\">Assigning syntactic dependency labels, describing the relations between individual tokens, like subject or object.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><strong>Lemmatization</strong></td><td class=\"_5c99da9a\">Assigning the base forms of words. For example, the lemma of “was” is “be”, and the lemma of “rats” is “rat”.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><strong>Sentence Boundary Detection</strong> (SBD)</td><td class=\"_5c99da9a\">Finding and segmenting individual sentences.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><strong>Named Entity Recognition</strong> (NER)</td><td class=\"_5c99da9a\">Labelling named “real-world” objects, like persons, companies or locations.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><strong>Similarity</strong></td><td class=\"_5c99da9a\">Comparing words, text spans and documents and how similar they are to each other.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><strong>Text Classification</strong></td><td class=\"_5c99da9a\">Assigning categories or labels to a whole document, or parts of a document.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><strong>Rule-based Matching</strong></td><td class=\"_5c99da9a\">Finding sequences of tokens based on their texts and linguistic annotations, similar to regular expressions.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><strong>Training</strong></td><td class=\"_5c99da9a\">Updating and improving a statistical model’s predictions.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><strong>Serialization</strong></td><td class=\"_5c99da9a\">Saving objects to files or byte strings.</td></tr></tbody></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "While some of spaCy’s features work independently, others require statistical models to be loaded, which enable spaCy to predict linguistic annotations – for example, whether a word is a verb or a noun.\n",
    "For a general-purpose use case, the small, default models are always a good start. They typically include the following components:\n",
    "\n",
    "* **Binary weights** for the part-of-speech tagger, dependency parser and named entity recognizer to predict those annotations in context.\n",
    "* **Lexical entries** in the vocabulary, i.e. words and their context-independent attributes like the shape or spelling.\n",
    "* **Word vectors**, i.e. multi-dimensional meaning representations of words that let you determine how similar they are to each other.\n",
    "* **Configuration** options, like the language and processing pipeline settings, to put spaCy in the correct state when you load in the model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you’ve downloaded and installed a model, you can load it via `spacy.load()`. This will return a Language object containing all components and data needed to process text. We usually call it *nlp*. Calling the *nlp* object on a string of text will return a processed **Doc**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Processing Pipelines\n",
    "\n",
    "- When you call nlp on a text, spaCy first **tokenizes** the text to produce a **Doc object**.\n",
    "- The Doc is then processed in several different steps – this is also referred to as the **processing pipeline**. \n",
    "- The pipeline used by the default models consists of a **tagger**, a **parser** and an **entity recognizer**.\n",
    "\n",
    "![pipeline](images/pipeline.svg)\n",
    "\n",
    "More info [here](https://spacy.io/usage/processing-pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "During processing, spaCy first tokenizes the text, i.e. segments it into words, punctuation and so on. This is done by applying rules specific to each language. For example, punctuation at the end of a sentence should be split off – whereas “U.K.” should remain one token. Each Doc consists of individual tokens, and we can iterate over them.\n",
    "\n",
    "First, the raw text is split on whitespace characters, similar to text.split(' '). Then, the tokenizer processes the text from left to right. On each substring, it performs two checks:\n",
    "\n",
    "1. **Does the substring match a tokenizer exception rule?** For example, “don’t” does not contain whitespace, but should be split into two tokens, “do” and “n’t”, while “U.K.” should always remain one token.\n",
    "2. **Can a prefix, suffix or infix be split off?** For example punctuation like commas, periods, hyphens or quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Hello, ,, world, ., How, are, you, ?]\n",
      "[Ich, bin, ein, Berliner, .]\n",
      "[Hola, ., Buenos, dias]\n",
      "[(0, Hello), (1, ,), (2, world), (3, .), (4, How), (5, are), (6, you), (7, ?)]\n",
      "1st Token: Hello\n",
      "Last Token: ?\n",
      "Slice from Token 3 to the end: world. How are you?\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(u\"Hello, world. How are you?\")\n",
    "print([ t for t in doc])\n",
    "\n",
    "nlp_de = spacy.load(\"de_core_news_sm\")\n",
    "doc_de = nlp_de(u\"Ich bin ein Berliner.\")\n",
    "print([t for t in doc_de])\n",
    "\n",
    "nlp_es = spacy.load(\"es_core_news_sm\")\n",
    "doc_es = nlp_de(u\"Hola. Buenos dias\")\n",
    "print([t for t in doc_es])\n",
    "\n",
    "print([ t for t in enumerate(doc)])\n",
    "print(\"1st Token:\", doc[0])          \n",
    "print(\"Last Token:\",doc[-1])\n",
    "print(\"Slice from Token 3 to the end:\",doc[2:].text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola\t0\tHola\tFalse\tFalse\tXxxx\t\t\n",
      "món\t5\tmón\tFalse\tFalse\txxx\t\t\n",
      ".\t8\t.\tTrue\tFalse\t.\t\t\n",
      "Molt\t10\tMolt\tFalse\tFalse\tXxxx\t\t\n",
      "bon\t15\tbo\tFalse\tFalse\txxx\t\t\n",
      "dia\t19\tdia\tFalse\tFalse\txxx\t\t\n",
      "!\t22\t!\tTrue\tFalse\t!\t\t\n"
     ]
    }
   ],
   "source": [
    "## Exists catalan Tokenizer, but there's not model yet!\n",
    "\n",
    "nlp_ca = spacy.blank(\"ca\")\n",
    "doc_ca = nlp_ca(u\"Hola món. Molt bon dia!\")\n",
    "for i,token in enumerate(doc_ca):\n",
    "    print(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\\t{6}\\t{7}\".format(\n",
    "        token.text,\n",
    "        token.idx,\n",
    "        token.lemma_,\n",
    "        token.is_punct,\n",
    "        token.is_space,\n",
    "        token.shape_,\n",
    "        token.pos_,\n",
    "        token.tag_\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello, world.', 'How are you?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s.text for s in doc.sents]    # Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-of-speech tags and flags \n",
    "\n",
    "What is a Speech Tag?\n",
    "A speech tag is a context sensitive description of what a word means in the context of the whole sentence. More information about the kinds of speech tags which are used in NLP can be found here.\n",
    "\n",
    "Examples:\n",
    "\n",
    "* CARDINAL, Cardinal Number - 1,2,3\n",
    "* PROPN, Proper Noun, Singular - \"Matic\", \"Andraz\", \"Cardiff\"\n",
    "* INTJ, Interjection - \"Uhhhhhhhhhhh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\tIndex\tLemma\tPunct?\tSpace?\tShape\tPOS\tTAG\tDEP\n",
      "\n",
      "Apple\t0\tApple\tFalse\tFalse\tXxxxx\tPROPN\tNNP\tnsubj\n",
      "is\t6\tbe\tFalse\tFalse\txx\tVERB\tVBZ\taux\n",
      "looking\t9\tlook\tFalse\tFalse\txxxx\tVERB\tVBG\tROOT\n",
      "at\t17\tat\tFalse\tFalse\txx\tADP\tIN\tprep\n",
      "buying\t20\tbuy\tFalse\tFalse\txxxx\tVERB\tVBG\tpcomp\n",
      "U.K.\t27\tU.K.\tFalse\tFalse\tX.X.\tPROPN\tNNP\tcompound\n",
      "startup\t32\tstartup\tFalse\tFalse\txxxx\tNOUN\tNN\tdobj\n",
      "for\t40\tfor\tFalse\tFalse\txxx\tADP\tIN\tprep\n",
      "$\t44\t$\tFalse\tFalse\t$\tSYM\t$\tquantmod\n",
      "1\t45\t1\tFalse\tFalse\td\tNUM\tCD\tcompound\n",
      "billion\t47\tbillion\tFalse\tFalse\txxxx\tNUM\tCD\tpobj\n",
      ".\t54\t.\tTrue\tFalse\t.\tPUNCT\t.\tpunct\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(u\"Apple is looking at buying U.K. startup for $1 billion.\")\n",
    "print(\"Text\\tIndex\\tLemma\\tPunct?\\tSpace?\\tShape\\tPOS\\tTAG\\tDEP\\n\")\n",
    "for i,token in enumerate(doc):\n",
    "    print(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\\t{6}\\t{7}\\t{8}\".format(\n",
    "        token.text,\n",
    "        token.idx,\n",
    "        token.lemma_,\n",
    "        token.is_punct,\n",
    "        token.is_space,\n",
    "        token.shape_,\n",
    "        token.pos_,\n",
    "        token.tag_,\n",
    "        token.dep_\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple POS tag: PROPN proper noun 96\n",
      "Detailed POS tag: NNP noun, proper singular 15794550382381185553\n",
      "Word shape: Xxxxx 16072095006890171862\n",
      "Alphanumeric characters? True\n",
      "Punctuation mark? False\n",
      "Digit? False\n",
      "Like a number? True\n",
      "Like an email address? False\n"
     ]
    }
   ],
   "source": [
    "apple = doc[0]\n",
    "print(\"Simple POS tag:\", apple.pos_, spacy.explain(apple.pos_),apple.pos)\n",
    "print(\"Detailed POS tag:\", apple.tag_,spacy.explain(apple.tag_), apple.tag )\n",
    "print(\"Word shape:\", apple.shape_, apple.shape)\n",
    "print(\"Alphanumeric characters?\", apple.is_alpha)\n",
    "print(\"Punctuation mark?\", apple.is_punct)\n",
    "\n",
    "billion = doc[10]\n",
    "print(\"Digit?\", billion.is_digit)\n",
    "print(\"Like a number?\", billion.like_num)\n",
    "print(\"Like an email address?\", billion.like_email)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are syntactic dependencies?\n",
    "\n",
    "We have the speech tags and we have all of the tokens in a sentence, but how do we relate the two to uncover the syntax in a sentence? Syntactic dependencies describe how each type of word relates to each other in a sentence, this is important in NLP in order to extract structure and understand grammar in plain text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c5ad0a9baf5945dbb526209eb4700b0a-0\" class=\"displacy\" width=\"1975\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">looking</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">buying</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">startup</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">1</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">billion.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5ad0a9baf5945dbb526209eb4700b0a-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5ad0a9baf5945dbb526209eb4700b0a-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5ad0a9baf5945dbb526209eb4700b0a-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5ad0a9baf5945dbb526209eb4700b0a-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5ad0a9baf5945dbb526209eb4700b0a-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5ad0a9baf5945dbb526209eb4700b0a-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5ad0a9baf5945dbb526209eb4700b0a-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5ad0a9baf5945dbb526209eb4700b0a-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M740.0,266.5 L748.0,254.5 732.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5ad0a9baf5945dbb526209eb4700b0a-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5ad0a9baf5945dbb526209eb4700b0a-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5ad0a9baf5945dbb526209eb4700b0a-0-5\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5ad0a9baf5945dbb526209eb4700b0a-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1095.0,266.5 L1103.0,254.5 1087.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5ad0a9baf5945dbb526209eb4700b0a-0-6\" stroke-width=\"2px\" d=\"M770,264.5 C770,2.0 1275.0,2.0 1275.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5ad0a9baf5945dbb526209eb4700b0a-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,266.5 L1283.0,254.5 1267.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5ad0a9baf5945dbb526209eb4700b0a-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,89.5 1795.0,89.5 1795.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5ad0a9baf5945dbb526209eb4700b0a-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5ad0a9baf5945dbb526209eb4700b0a-0-8\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5ad0a9baf5945dbb526209eb4700b0a-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,266.5 L1637,254.5 1653,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5ad0a9baf5945dbb526209eb4700b0a-0-9\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,2.0 1800.0,2.0 1800.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5ad0a9baf5945dbb526209eb4700b0a-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1800.0,266.5 L1808.0,254.5 1792.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noun Chunks\n",
    "\n",
    "Noun chunks are the phrases based upon nouns recovered from tokenized text using the speech tags.\n",
    "\n",
    "Example:\n",
    "\n",
    "The sentence \"The boy saw the yellow dog\" has 2 noun objects, the boy and the dog. \n",
    "Therefore the noun chunks will be\n",
    "\n",
    "\t1. \"The boy\"\n",
    "\t2. \"the yellow dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'Paris', 'I', 'my old friend', 'Jack', 'uni']"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(u\"I went to Paris where I met my old friend Jack from uni.\")\n",
    "\n",
    "[ch.text for ch in doc.noun_chunks] #noun Chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition\n",
    "\n",
    "A named entity is any real world object such as a person, location, organisation or product with a proper name. \n",
    "\n",
    "Example:\n",
    "\n",
    "\t1. Barack Obama\n",
    "\t2. Edinburgh\n",
    "\t3. Ferrari Enzo\n",
    "    \n",
    "spaCy can recognise various types of named entities in a document, by asking the model for a prediction. Because models are statistical and strongly depend on the examples they were trained on, this doesn't always work perfectly and might need some tuning later, depending on your use case.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Doing NER with spaCy is super easy and the pretrained model performs pretty well:\n",
    "    \n",
    "\n",
    "- **PERSON**: People, including fictional.\n",
    "- **NORP**: Nationalities or religious or political groups.\n",
    "- **FAC**: Buildings, airports, highways, bridges, etc.\n",
    "- **ORG**: Companies, agencies, institutions, etc.\n",
    "- **GPE**: Countries, cities, states.\n",
    "- **LOC**: Non-GPE locations, mountain ranges, bodies of water.\n",
    "- **PRODUCT**: Objects, vehicles, foods, etc. (Not services.)\n",
    "- **EVENT**: Named hurricanes, battles, wars, sports events, etc.\n",
    "- **WORK_OF_ART**: Titles of books, songs, etc.\n",
    "- **LAW**: Named documents made into laws. \n",
    "- **LANGUAGE**: Any named language.\n",
    "- **DATE**: Absolute or relative dates or periods.\n",
    "- **TIME**: Times smaller than a day.\n",
    "- **PERCENT**: Percentage, including \"%\".\n",
    "- **MONEY**: Monetary values, including unit.\n",
    "- **QUANTITY**: Measurements, as of weight or distance.\n",
    "- **ORDINAL**: \" , \"second\", etc.\n",
    "- **CARDINAL**: Numerals that do not fall under another type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "San Francisco 0 13 GPE\n",
      "Amazon 0 6 ORG\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(u\"San Francisco considers banning sidewalk delivery robots\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "\n",
    "doc = nlp(u\"Amazon is hiring a new VP of global policy\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add new NE using Span:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No entities found\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"Facebook is hiring a new VP of global policy\")\n",
    "if doc.ents:\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "else:\n",
    "    print(\"No entities found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facebook 0 8 ORG\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "doc = nlp(u\"Facebook is hiring a new VP of global policy\")\n",
    "doc.ents = [Span(doc, 0, 1, label=doc.vocab.strings[u\"ORG\"])]\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of Entities in the pretrained model. You can uses `spacy.explain` to obtain more information about them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def explain_text_entities(text):\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        print(f'Entity: {ent}, Label: {ent.label_}, {spacy.explain(ent.label_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Next week, Label: DATE, Absolute or relative dates or periods\n",
      "Entity: London, Label: GPE, Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "explain_text_entities(\"Next week I'll be in London.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: 2, Label: CARDINAL, Numerals that do not fall under another type\n",
      "Entity: 9 a.m., Label: TIME, Times smaller than a day\n",
      "Entity: 30%, Label: PERCENT, Percentage, including \"%\"\n",
      "Entity: just 2 days, Label: DATE, Absolute or relative dates or periods\n",
      "Entity: WSJ, Label: ORG, Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "explain_text_entities(\"I just bought 2 shares at 9 a.m. because the stock went up 30% in just 2 days according to the WSJ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`displacy` comes in handy for a better visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">When \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Sebastian Thrun\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " started working on self-driving cars at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    2007\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", few people outside of the company took him seriously.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_ent = nlp(u\"When Sebastian Thrun started working on self-driving cars at Google \"\n",
    "              u\"in 2007, few people outside of the company took him seriously.\")\n",
    "displacy.render(doc_ent, style=\"ent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embedding vectors and similarity\n",
    "\n",
    "A word embedding is a representation of a word, and by extension a whole language corpus, in a vector or other form of numerical mapping. This allows words to be treated numerically with word similarity represented as spatial difference in the dimensions of the word embedding mapping.\n",
    "\n",
    "Example:\n",
    "\t\n",
    "With word embeddings we can understand that vector operations describe word similarity. This means that we can see vector proofs of statements such as:\n",
    "\n",
    "\tking-queen==man-woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True True\n",
      "apple <-> banana 0.5831845\n",
      "pasta <-> hippo 0.12069741\n",
      "0.657017\n",
      "0.48992792\n"
     ]
    }
   ],
   "source": [
    "import en_core_web_md\n",
    "nlp = en_core_web_md.load()\n",
    "doc = nlp(u\"Apple and banana are similar. Pasta and hippo aren't.\")\n",
    "\n",
    "apple = doc[0]\n",
    "banana = doc[2]\n",
    "pasta = doc[6]\n",
    "hippo = doc[8]\n",
    "\n",
    "print(apple.has_vector, banana.has_vector, pasta.has_vector, hippo.has_vector)\n",
    "\n",
    "print(\"apple <-> banana\", apple.similarity(banana))\n",
    "print(\"pasta <-> hippo\", pasta.similarity(hippo))\n",
    "\n",
    "apples_sent, boots_sent = doc.sents\n",
    "fruit = doc.vocab[u'fruit']\n",
    "print(apples_sent.similarity(fruit))\n",
    "print(boots_sent.similarity(fruit))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a new model\n",
    "We can train a catalan model with the data found in https://github.com/UniversalDependencies/UD_Catalan-AnCora\n",
    "following the steps  in https://spacy.io/usage/training\n",
    "\n",
    "Gonna try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\tIndex\tLemma\tPunct?\tSpace?\tShape\tPOS\tTAG\n",
      "\n",
      "Ahir\t0\tAhir\tFalse\tFalse\tXxxx\tADV\tADV\n",
      "el\t5\tell\tFalse\tFalse\txx\tDET\tDET\n",
      "noi\t8\tnoi\tFalse\tFalse\txxx\tNOUN\tNOUN\n",
      "de\t12\tde\tFalse\tFalse\txx\tADP\tADP\n",
      "la\t15\tell\tFalse\tFalse\txx\tDET\tDET\n",
      "mare\t18\tmare\tFalse\tFalse\txxxx\tNOUN\tNOUN\n",
      "va\t23\tanar\tFalse\tFalse\txx\tAUX\tAUX\n",
      "anar\t26\tanar\tFalse\tFalse\txxxx\tVERB\tVERB\n",
      "a\t31\ta\tFalse\tFalse\tx\tADP\tADP\n",
      "comprar\t33\tcomprar\tFalse\tFalse\txxxx\tVERB\tVERB\n",
      "dos\t41\tdosar\tFalse\tFalse\txxx\tNUM\tNUM\n",
      "pastissos\t45\tpastís\tFalse\tFalse\txxxx\tNOUN\tNOUN\n",
      "0\n",
      "1\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"ca\" id=\"770cec1325ab43b481206943c6b026fa-0\" class=\"displacy\" width=\"2150\" height=\"574.5\" direction=\"ltr\" style=\"max-width: none; height: 574.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Ahir</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">el</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">noi</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">de</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">la</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">mare</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">va</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">anar</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">comprar</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">dos</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">pastissos</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-770cec1325ab43b481206943c6b026fa-0-0\" stroke-width=\"2px\" d=\"M70,439.5 C70,2.0 1275.0,2.0 1275.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-770cec1325ab43b481206943c6b026fa-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,441.5 L62,429.5 78,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-770cec1325ab43b481206943c6b026fa-0-1\" stroke-width=\"2px\" d=\"M245,439.5 C245,352.0 380.0,352.0 380.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-770cec1325ab43b481206943c6b026fa-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,441.5 L237,429.5 253,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-770cec1325ab43b481206943c6b026fa-0-2\" stroke-width=\"2px\" d=\"M420,439.5 C420,89.5 1270.0,89.5 1270.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-770cec1325ab43b481206943c6b026fa-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,441.5 L412,429.5 428,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-770cec1325ab43b481206943c6b026fa-0-3\" stroke-width=\"2px\" d=\"M595,439.5 C595,264.5 910.0,264.5 910.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-770cec1325ab43b481206943c6b026fa-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,441.5 L587,429.5 603,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-770cec1325ab43b481206943c6b026fa-0-4\" stroke-width=\"2px\" d=\"M770,439.5 C770,352.0 905.0,352.0 905.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-770cec1325ab43b481206943c6b026fa-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,441.5 L762,429.5 778,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-770cec1325ab43b481206943c6b026fa-0-5\" stroke-width=\"2px\" d=\"M420,439.5 C420,177.0 915.0,177.0 915.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-770cec1325ab43b481206943c6b026fa-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,441.5 L923.0,429.5 907.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-770cec1325ab43b481206943c6b026fa-0-6\" stroke-width=\"2px\" d=\"M1120,439.5 C1120,352.0 1255.0,352.0 1255.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-770cec1325ab43b481206943c6b026fa-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,441.5 L1112,429.5 1128,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-770cec1325ab43b481206943c6b026fa-0-7\" stroke-width=\"2px\" d=\"M1470,439.5 C1470,352.0 1605.0,352.0 1605.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-770cec1325ab43b481206943c6b026fa-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,441.5 L1462,429.5 1478,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-770cec1325ab43b481206943c6b026fa-0-8\" stroke-width=\"2px\" d=\"M1295,439.5 C1295,264.5 1610.0,264.5 1610.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-770cec1325ab43b481206943c6b026fa-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1610.0,441.5 L1618.0,429.5 1602.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-770cec1325ab43b481206943c6b026fa-0-9\" stroke-width=\"2px\" d=\"M1820,439.5 C1820,352.0 1955.0,352.0 1955.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-770cec1325ab43b481206943c6b026fa-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,441.5 L1812,429.5 1828,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-770cec1325ab43b481206943c6b026fa-0-10\" stroke-width=\"2px\" d=\"M1645,439.5 C1645,264.5 1960.0,264.5 1960.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-770cec1325ab43b481206943c6b026fa-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1960.0,441.5 L1968.0,429.5 1952.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "nlp_ca = spacy.load(\"./model-ca-best\")\n",
    "doc_ca = nlp_ca(u'Ahir el noi de la mare va anar a comprar dos pastissos')\n",
    "print(\"Text\\tIndex\\tLemma\\tPunct?\\tSpace?\\tShape\\tPOS\\tTAG\\n\")\n",
    "for i,token in enumerate(doc_ca):\n",
    "    print(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\\t{6}\\t{7}\".format(\n",
    "        token.text,\n",
    "        token.idx,\n",
    "        token.lemma_,\n",
    "        token.is_punct,\n",
    "        token.is_space,\n",
    "        token.shape_,\n",
    "        token.pos_,\n",
    "        token.tag_\n",
    "    ))\n",
    "    \n",
    "print( len(list(doc_ca.noun_chunks)))\n",
    "print( len(list(doc_ca.sents)))\n",
    "print( len(list(doc_ca.ents)))\n",
    "\n",
    "displacy.render(doc_ca, style=\"dep\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "[Pride and perdjudice](01_pride_and_predjudice.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Model  with genism\n",
    "\n",
    "[Topic modelling](topic_modelling.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    " [INTRODUCTION TO SENTIMENT ANALYSIS WITH SPACY, by Thomas Aglassinger at europython 2018](https://ep2018.europython.eu/conference/talks/introduction-to-sentiment-analysis-with-spacy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
